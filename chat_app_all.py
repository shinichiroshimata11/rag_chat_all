#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
All-Brands RAG Chatbot (Qdrant + OpenAI embeddings + Anthropic)
- æ—¥æœ¬èªUI
- ãƒ–ãƒ©ãƒ³ãƒ‰çµã‚Šè¾¼ã¿ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³
- Qdrantã®payloadã«ã¯ page_contentï¼ˆæœ¬æ–‡ï¼‰/ brand / qa_id / resolved_at / ticket_number ãŒå…¥ã£ã¦ã„ã‚‹æƒ³å®š
"""

import os
from typing import List, Dict, Any, Set

import streamlit as st
from langchain_openai import OpenAIEmbeddings
from langchain_anthropic import ChatAnthropic
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.vectorstores import Qdrant as QdrantVS
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue


# -------------------- helpers --------------------
def need_env(var: str) -> str:
    val = os.getenv(var)
    if not val:
        raise RuntimeError(f"{var} ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆç’°å¢ƒå¤‰æ•°ï¼‰ã€‚")
    return val


def doc_text(d) -> str:
    """å®‰å…¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆpage_contentå„ªå…ˆã€ç„¡ã‘ã‚Œã°metadataçµŒç”±ï¼‰"""
    return (getattr(d, "page_content", None)
            or d.metadata.get("page_content")
            or d.metadata.get("answer")
            or "")


def mget(md: Dict[str, Any], key: str, default: str = "") -> str:
    v = md.get(key)
    return default if v is None else str(v)


def render_health(client: QdrantClient, collection: str):
    try:
        info = client.get_collection(collection)
        st.success(f"Qdrantæ¥ç¶šOKï¼šã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ **{collection}**ï¼ˆstatus: {info.status}ï¼‰")
    except Exception as e:
        st.error(f"Qdrantæ¥ç¶š/ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç¢ºèªã«å¤±æ•—: {e}")


def fetch_brand_options(client: QdrantClient, collection: str, max_scan: int = 300) -> List[str]:
    """
    Qdrantã«ã¯é›†è¨ˆAPIãŒãªã„ãŸã‚ã€scrollã§å…ˆé ­ max_scan ä»¶ã‚’è¦—ã„ã¦ãƒ–ãƒ©ãƒ³ãƒ‰å€™è£œã‚’ä½œã‚‹ã€‚
    ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã‚‹ãŸã‚å–ã‚Šéããªã„è¨­è¨ˆã€‚
    """
    uniq: Set[str] = set()
    next_offset = None
    remaining = max_scan
    while remaining > 0:
        limit = min(100, remaining)
        points, next_offset = client.scroll(
            collection_name=collection,
            limit=limit,
            with_payload=True,
            offset=next_offset,
        )
        for p in points:
            b = p.payload.get("brand")
            if b:
                uniq.add(str(b))
        remaining -= len(points)
        if not next_offset or len(points) == 0:
            break
    return sorted(uniq)


# -------------------- prompt --------------------
PROMPT = PromptTemplate(
    input_variables=["context", "question"],
    template=(
        "ã‚ãªãŸã¯æ—¥è‹±ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ã®ã‚µãƒãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚\n"
        "ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æƒ…å ±ã®ã¿ã«åŸºã¥ã„ã¦ã€ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
        "ã‚‚ã—ç­”ãˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’è¿°ã¹ã¦ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚\n\n"
        "ãƒ«ãƒ¼ãƒ«:\n"
        "- å›ç­”å†…ã«**ã‚½ãƒ¼ã‚¹ã®ãƒ–ãƒ©ãƒ³ãƒ‰å**ã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚\n"
        "- é©åˆ‡ãªå ´åˆã¯ç•ªå·ä»˜ãæ‰‹é †ã‚’ä½¿ã†ã“ã¨ã€‚\n"
        "- ãƒãƒ¼ã‚¸ãƒ§ãƒ³å·®ç•°ãƒ»ãƒªã‚¹ã‚¯ãŒã‚ã‚Œã°æ³¨æ„æ›¸ãã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚\n"
        "- æœ€å¾Œã« (brand, qa_id, resolved_at, ticket_number) ã‚’åˆ—æŒ™ã™ã‚‹ã“ã¨ã€‚\n\n"
        "â€”â€” ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ â€”â€”\n{context}\nâ€”â€” ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã“ã“ã¾ã§ â€”â€”\n\n"
        "è³ªå•: {question}\n"
        "å›ç­”:"
    )
)


# -------------------- app --------------------
def main():
    st.set_page_config(page_title="å…¨ãƒ–ãƒ©ãƒ³ãƒ‰RAGã‚µãƒãƒ¼ãƒˆ", page_icon="ğŸ’¬", layout="wide")
    st.title("å…¨ãƒ–ãƒ©ãƒ³ãƒ‰ ã‚µãƒãƒ¼ãƒˆRAG ğŸ’¬")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ & ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼‰
    with st.sidebar:
        st.markdown("### ğŸ”§ æ¥ç¶šãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯")
        oa = os.getenv("OPENAI_API_KEY", "")
        an = os.getenv("ANTHROPIC_API_KEY", "")
        qurl = os.getenv("QDRANT_URL", "")
        qkey = os.getenv("QDRANT_API_KEY", "")
        qcol = os.getenv("QDRANT_COLLECTION", "support_logs_all")

        st.code(
            f"""OPENAI_API_KEY      = {oa[:4]}â€¦{oa[-4:] if oa else ''}
ANTHROPIC_API_KEY   = {an[:4]}â€¦{an[-4:] if an else ''}
QDRANT_URL          = {qurl}
QDRANT_COLLECTION   = {qcol}
""",
            language="bash",
        )

    # å¿…é ˆç’°å¢ƒå¤‰æ•°
    openai_key = need_env("OPENAI_API_KEY")
    anthropic_key = need_env("ANTHROPIC_API_KEY")
    qdrant_url = need_env("QDRANT_URL")
    qdrant_key = need_env("QDRANT_API_KEY")
    collection = os.getenv("QDRANT_COLLECTION", "support_logs_all")

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    qclient = QdrantClient(url=qdrant_url, api_key=qdrant_key)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=openai_key)

    # VectorStoreï¼ˆcontent_payload_key=page_content å‰æï¼‰
    vectordb = QdrantVS(client=qclient, collection_name=collection, embeddings=embeddings)
    retriever = vectordb.as_retriever(search_kwargs={"k": 5})

    with st.sidebar:
        render_health(qclient, collection)

    # ========= ã‚ªãƒ—ã‚·ãƒ§ãƒ³&ãƒ–ãƒ©ãƒ³ãƒ‰çµã‚Šè¾¼ã¿ =========
    with st.expander("ã‚ªãƒ—ã‚·ãƒ§ãƒ³ / Options", expanded=True):
        # ãƒ–ãƒ©ãƒ³ãƒ‰å€™è£œã®å–å¾—ï¼ˆè»½é‡ã‚¹ã‚­ãƒ£ãƒ³ï¼‰
        brand_options = ["ï¼ˆã™ã¹ã¦ï¼‰"] + fetch_brand_options(qclient, collection, max_scan=300)
        sel_brand = st.selectbox("ãƒ–ãƒ©ãƒ³ãƒ‰ã§çµã‚Šè¾¼ã¿", brand_options, index=0, help="Qdrantã®payload.brandã§ãƒ•ã‚£ãƒ«ã‚¿ã—ã¾ã™")
        k = st.slider("Top-Kï¼ˆå–å¾—ä»¶æ•°ï¼‰", 1, 10, 5, help="ä¸Šä½ä½•ä»¶ã®é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½¿ã†ã‹")
        temperature = st.slider("æ¸©åº¦ï¼ˆå¤šæ§˜æ€§ï¼‰", 0.0, 1.0, 0.2, 0.1, help="æ•°å€¤ãŒé«˜ã„ã»ã©å‡ºåŠ›ãŒå¤šæ§˜ã«ãªã‚Šã¾ã™")

    # ãƒ•ã‚£ãƒ«ã‚¿è¨­å®šï¼ˆé¸æŠã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰
    if sel_brand and sel_brand != "ï¼ˆã™ã¹ã¦ï¼‰":
        retriever.search_kwargs["filter"] = Filter(
            must=[FieldCondition(key="brand", match=MatchValue(value=sel_brand))]
        )
    else:
        # æ—¢å­˜ã®filterãŒæ®‹ã‚‰ãªã„ã‚ˆã†æ˜ç¤ºå‰Šé™¤
        retriever.search_kwargs.pop("filter", None)

    # ========= å…¥åŠ›ï¼†å®Ÿè¡Œ =========
    query = st.text_input("è³ªå•", placeholder="ä¾‹: CegidãŒãƒ•ãƒªãƒ¼ã‚ºã—ãŸæ™‚ã®å¯¾å‡¦ã¯ï¼Ÿ / What to do when Cegid freezes?")
    ask = st.button("å®Ÿè¡Œï¼ˆAskï¼‰")

    if not ask or not query.strip():
        return

    # å–å¾—
    try:
        retriever.search_kwargs["k"] = k
        candidates = retriever.get_relevant_documents(query)
    except Exception as e:
        st.error(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\n{e}")
        return

    usable = [d for d in candidates if doc_text(d)]
    if not usable:
        st.warning("è©²å½“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰/Top-Kï¼‰ã‚’èª¿æ•´ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    # è¨¼æ‹ ï¼ˆEvidenceï¼‰
    st.markdown("### ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼ˆEvidenceï¼‰")
    for i, d in enumerate(usable, 1):
        brand = mget(d.metadata, "brand", "N/A")
        qa_id = mget(d.metadata, "qa_id", "N/A")
        resolved = mget(d.metadata, "resolved_at", "N/A")
        ticket = mget(d.metadata, "ticket_number", "N/A")
        st.write(f"{i}. brand={brand}, qa_id={qa_id}, resolved_at={resolved}, ticket={ticket}")
        with st.expander(f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆ {i}", expanded=False):
            st.write(doc_text(d))

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
    context_blocks = []
    for d in usable:
        brand = mget(d.metadata, "brand")
        qa_id = mget(d.metadata, "qa_id")
        resolved = mget(d.metadata, "resolved_at")
        ticket = mget(d.metadata, "ticket_number")
        context_blocks.append(
            f"[brand={brand} qa_id={qa_id} resolved_at={resolved} ticket={ticket}]\n{doc_text(d)}"
        )
    context = "\n\n---\n\n".join(context_blocks)

    # ãƒ¢ãƒ‡ãƒ«
    llm = ChatAnthropic(model="claude-3-5-haiku-20241022", temperature=temperature, api_key=anthropic_key)
    chain = LLMChain(llm=llm, prompt=PROMPT)

    with st.spinner("ç”Ÿæˆä¸­â€¦ / Thinkingâ€¦"):
        answer = chain.run({"context": context, "question": query})

    st.markdown("### å›ç­”ï¼ˆAnswerï¼‰")
    st.write(answer)


if __name__ == "__main__":
    main()
