#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
All-Brands RAG Chatbot (Qdrant + OpenAI embeddings + Anthropic)
- æ—¥æœ¬èªUI
- ãƒ–ãƒ©ãƒ³ãƒ‰çµã‚Šè¾¼ã¿ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³
- é ‘å¥ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆbrand / qa_id / resolved_at / ticket_numberï¼‰
"""

import os
from typing import Any, Dict, Iterable, List, Set

import streamlit as st
from langchain_openai import OpenAIEmbeddings
from langchain_anthropic import ChatAnthropic
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.vectorstores import Qdrant as QdrantVS
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue


# -------------------- helpers --------------------
def need_env(var: str) -> str:
    val = os.getenv(var)
    if not val:
        raise RuntimeError(f"{var} ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆç’°å¢ƒå¤‰æ•°ï¼‰ã€‚")
    return val


def _flatten_dict(d: Dict[str, Any], depth: int = 2) -> Dict[str, Any]:
    """
    å°ã•ã„æ·±ã•ã§ãƒã‚¹ãƒˆè¾æ›¸ã‚’å¹³å¦åŒ–ã™ã‚‹ã€‚ã‚­ãƒ¼è¡çªã¯ä¸Šæ›¸ãOKã€‚
    ä¾‹: {'payload': {...}, 'qdrant__payload': {...}} ã‚’ä¸€ã¤ã«ã¾ã¨ã‚ã‚‹ã€‚
    """
    out: Dict[str, Any] = {}
    if not isinstance(d, dict):
        return out
    stack: List[tuple[Dict[str, Any], int]] = [(d, 0)]
    while stack:
        cur, lvl = stack.pop()
        for k, v in cur.items():
            if isinstance(v, dict) and lvl < depth:
                stack.append((v, lvl + 1))
            else:
                if v is not None:
                    out[k] = v
    return out


def collect_metadata(doc) -> Dict[str, Any]:
    """
    LangChainã®Document.metadataã®ä¸­ã«ã€å®Ÿéš›ã®Qdrant payloadãŒ
    ã„ã‚ã„ã‚ãªã‚­ãƒ¼ã§å…¥ã‚‹å ´åˆã«å¯¾å¿œï¼ˆ'payload', 'qdrant__payload', 'document' ãªã©ï¼‰ã€‚
    """
    md: Dict[str, Any] = {}

    # 1) ã¾ãš doc.metadata è‡ªä½“
    if hasattr(doc, "metadata") and isinstance(doc.metadata, dict):
        md.update(_flatten_dict(doc.metadata))

        # 2) ã‚ˆãã‚ã‚‹ãƒã‚¹ãƒˆå€™è£œã‚’é †ã«çµ±åˆ
        for k in ("payload", "qdrant__payload", "document", "metadata", "data"):
            if k in doc.metadata and isinstance(doc.metadata[k], dict):
                md.update(_flatten_dict(doc.metadata[k]))

    # 3) å¿µã®ãŸã‚ doc.dict() å†…ã‚‚è¦‹ã‚‹ï¼ˆå®Ÿè£…å·®ç•°ã¸ã®ä¿é™ºï¼‰
    try:
        as_dict = getattr(doc, "dict", None)
        if callable(as_dict):
            d_all = doc.dict()
            if "metadata" in d_all and isinstance(d_all["metadata"], dict):
                md.update(_flatten_dict(d_all["metadata"]))
    except Exception:
        pass

    return md


def doc_text(doc) -> str:
    """
    æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«æŠ½å‡ºã€‚
    å„ªå…ˆ: doc.page_content -> payload.page_content -> payload.answer -> "".
    """
    # 1) page_content ãŒå…¥ã£ã¦ã„ã‚Œã°æœ€å„ªå…ˆ
    if getattr(doc, "page_content", None):
        return doc.page_content

    # 2) ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ‹¾ã†
    md = collect_metadata(doc)
    for key in ("page_content", "text", "answer", "content", "body"):
        if md.get(key):
            return str(md[key])

    # 3) æœ€å¾Œã®ä¿é™ºï¼šquestion + answer ã®é€£çµï¼ˆä¸¡æ–¹ã‚ã‚Œã°ï¼‰
    q = md.get("question")
    a = md.get("answer")
    if q or a:
        return f"Q: {q or ''}\nA: {a or ''}".strip()

    return ""


def meta_get(md: Dict[str, Any], candidates: Iterable[str], default: str = "N/A") -> str:
    for k in candidates:
        v = md.get(k)
        if v not in (None, "", "null", "None"):
            return str(v)
    return default


def render_health(client: QdrantClient, collection: str):
    try:
        info = client.get_collection(collection)
        st.success(f"Qdrantæ¥ç¶šOKï¼šã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ **{collection}**ï¼ˆstatus: {info.status}ï¼‰")
    except Exception as e:
        st.error(f"Qdrantæ¥ç¶š/ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç¢ºèªã«å¤±æ•—: {e}")


def fetch_brand_options(client: QdrantClient, collection: str, max_scan: int = 300) -> List[str]:
    uniq: Set[str] = set()
    next_offset = None
    remaining = max_scan
    while remaining > 0:
        limit = min(100, remaining)
        points, next_offset = client.scroll(
            collection_name=collection,
            limit=limit,
            with_payload=True,
            offset=next_offset,
        )
        for p in points:
            b = p.payload.get("brand")
            if b:
                uniq.add(str(b))
        remaining -= len(points)
        if not next_offset or len(points) == 0:
            break
    return sorted(uniq)


# -------------------- prompt --------------------
PROMPT = PromptTemplate(
    input_variables=["context", "question"],
    template=(
        "ã‚ãªãŸã¯æ—¥è‹±ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ã®ã‚µãƒãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚\n"
        "ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æƒ…å ±ã®ã¿ã«åŸºã¥ã„ã¦ã€ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
        "ã‚‚ã—ç­”ãˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’è¿°ã¹ã¦ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚\n\n"
        "ãƒ«ãƒ¼ãƒ«:\n"
        "- å›ç­”å†…ã«**ã‚½ãƒ¼ã‚¹ã®ãƒ–ãƒ©ãƒ³ãƒ‰å**ã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚\n"
        "- é©åˆ‡ãªå ´åˆã¯ç•ªå·ä»˜ãæ‰‹é †ã‚’ä½¿ã†ã“ã¨ã€‚\n"
        "- ãƒãƒ¼ã‚¸ãƒ§ãƒ³å·®ç•°ãƒ»ãƒªã‚¹ã‚¯ãŒã‚ã‚Œã°æ³¨æ„æ›¸ãã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚\n"
        "- æœ€å¾Œã« (brand, qa_id, resolved_at, ticket_number) ã‚’åˆ—æŒ™ã™ã‚‹ã“ã¨ã€‚\n\n"
        "â€”â€” ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ â€”â€”\n{context}\nâ€”â€” ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã“ã“ã¾ã§ â€”â€”\n\n"
        "è³ªå•: {question}\n"
        "å›ç­”:"
    )
)


# -------------------- app --------------------
def main():
    st.set_page_config(page_title="å…¨ãƒ–ãƒ©ãƒ³ãƒ‰RAGã‚µãƒãƒ¼ãƒˆ", page_icon="ğŸ’¬", layout="wide")
    st.title("å…¨ãƒ–ãƒ©ãƒ³ãƒ‰ ã‚µãƒãƒ¼ãƒˆRAG ğŸ’¬")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã®ç°¡æ˜“è¡¨ç¤ºï¼‰
    with st.sidebar:
        st.markdown("### ğŸ”§ æ¥ç¶šãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯")
        oa = os.getenv("OPENAI_API_KEY", "")
        an = os.getenv("ANTHROPIC_API_KEY", "")
        qurl = os.getenv("QDRANT_URL", "")
        qkey = os.getenv("QDRANT_API_KEY", "")
        qcol = os.getenv("QDRANT_COLLECTION", "support_logs_all")

        st.code(
            f"""OPENAI_API_KEY      = {oa[:4]}â€¦{oa[-4:] if oa else ''}
ANTHROPIC_API_KEY   = {an[:4]}â€¦{an[-4:] if an else ''}
QDRANT_URL          = {qurl}
QDRANT_COLLECTION   = {qcol}
""",
            language="bash",
        )

    # å¿…é ˆENV
    openai_key = need_env("OPENAI_API_KEY")
    anthropic_key = need_env("ANTHROPIC_API_KEY")
    qdrant_url = need_env("QDRANT_URL")
    qdrant_key = need_env("QDRANT_API_KEY")
    collection = os.getenv("QDRANT_COLLECTION", "support_logs_all")

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ»ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢
    qclient = QdrantClient(url=qdrant_url, api_key=qdrant_key)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=openai_key)
    vectordb = QdrantVS(client=qclient, collection_name=collection, embeddings=embeddings)
    retriever = vectordb.as_retriever(search_kwargs={"k": 5})

    with st.sidebar:
        render_health(qclient, collection)

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    with st.expander("ã‚ªãƒ—ã‚·ãƒ§ãƒ³ / Options", expanded=True):
        brand_options = ["ï¼ˆã™ã¹ã¦ï¼‰"] + fetch_brand_options(qclient, collection, max_scan=300)
        sel_brand = st.selectbox("ãƒ–ãƒ©ãƒ³ãƒ‰ã§çµã‚Šè¾¼ã¿", brand_options, index=0)
        k = st.slider("Top-Kï¼ˆå–å¾—ä»¶æ•°ï¼‰", 1, 10, 5)
        temperature = st.slider("æ¸©åº¦ï¼ˆå¤šæ§˜æ€§ï¼‰", 0.0, 1.0, 0.2, 0.1)
        show_debug = st.checkbox("ãƒ‡ãƒãƒƒã‚°: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", value=False)

    if sel_brand and sel_brand != "ï¼ˆã™ã¹ã¦ï¼‰":
        retriever.search_kwargs["filter"] = Filter(
            must=[FieldCondition(key="brand", match=MatchValue(value=sel_brand))]
        )
    else:
        retriever.search_kwargs.pop("filter", None)

    query = st.text_input("è³ªå•", placeholder="ä¾‹: CegidãŒãƒ•ãƒªãƒ¼ã‚ºã—ãŸæ™‚ã®å¯¾å‡¦ã¯ï¼Ÿ")
    ask = st.button("å®Ÿè¡Œï¼ˆAskï¼‰")

    if not ask or not query.strip():
        return

    # å–å¾—
    try:
        retriever.search_kwargs["k"] = k
        candidates = retriever.get_relevant_documents(query)
    except Exception as e:
        st.error(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\n{e}")
        return

    usable = [d for d in candidates if doc_text(d)]
    if not usable:
        st.warning("è©²å½“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ========= ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ =========
    st.markdown("### ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼ˆEvidenceï¼‰")
    citations: List[str] = []
    context_blocks: List[str] = []

    for i, d in enumerate(usable, 1):
        md_all = collect_metadata(d)

        brand = meta_get(md_all, ("brand",))
        qa_id = meta_get(md_all, ("qa_id", "qaid", "qaId"))
        resolved = meta_get(md_all, ("resolved_at", "resolvedAt", "date", "resolved"))
        ticket = meta_get(md_all, ("ticket_number", "ticket", "ticket_no"))

        # ã“ã“ã§ N/A ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã€question/answer ã‹ã‚‰æ¨æ¸¬è£œå®Œã‚‚å¯èƒ½ï¼ˆå¿…è¦ãªã‚‰æœ‰åŠ¹åŒ–ï¼‰
        # if brand == "N/A" and md_all.get("question"):
        #     brand = "ä¸æ˜ãƒ–ãƒ©ãƒ³ãƒ‰"

        citations.append(f"({brand}, {qa_id}, {resolved}, {ticket})")

        st.markdown(f"**{i}. brand={brand}, qa_id={qa_id}, resolved_at={resolved}, ticket={ticket}**")
        with st.expander(f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆ {i}", expanded=False):
            st.write(doc_text(d))
            if show_debug:
                st.caption("â†“ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ãƒ©ãƒƒãƒˆåŒ–å¾Œï¼‰")
                st.json(md_all)

        context_blocks.append(
            f"[brand={brand} qa_id={qa_id} resolved_at={resolved} ticket={ticket}]\n{doc_text(d)}"
        )

    context = "\n\n---\n\n".join(context_blocks)
    citations_text = "\n".join(citations)

    # ãƒ¢ãƒ‡ãƒ«
    llm = ChatAnthropic(model="claude-3-5-haiku-20241022", temperature=temperature, api_key=anthropic_key)
    chain = LLMChain(llm=llm, prompt=PROMPT)

    with st.spinner("ç”Ÿæˆä¸­â€¦ / Thinkingâ€¦"):
        answer = chain.run({"context": context, "question": query})

    st.markdown("### å›ç­”ï¼ˆAnswerï¼‰")
    st.write(answer)

    st.markdown("### å¼•ç”¨ï¼ˆCitationsï¼‰")
    st.text(citations_text)


if __name__ == "__main__":
    main()
